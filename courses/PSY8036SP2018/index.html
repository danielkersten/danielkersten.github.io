<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html class=no-js lang=en> <!--<![endif]--> <head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=author content="Daniel Kersten"><link rel="shortcut icon" href=../../img/favicon.ico><title>PSY8036SP2018 - Computational Vision Lab</title><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700"><link rel=stylesheet href=../../css/theme.css><link rel=stylesheet href=../../css/theme_extra.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css><script>
    // Current page data
    var mkdocs_page_name = "PSY8036SP2018";
    var mkdocs_page_input_path = "courses/PSY8036SP2018.md";
    var mkdocs_page_url = null;
  </script><script src=../../js/jquery-2.1.1.min.js defer></script><script src=../../js/modernizr-2.8.3.min.js defer></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script></head> <body class=wy-body-for-nav role=document> <div class=wy-grid-for-nav> <nav data-toggle=wy-nav-shift class="wy-nav-side stickynav"> <div class=wy-side-scroll> <div class=wy-side-nav-search> <a href=../.. class="icon icon-home"> Computational Vision Lab</a> <div role=search> <form id=rtd-search-form class=wy-form action=../../search.html method=get> <input type=text name=q placeholder="Search docs" title="Type search term here"> </form> </div> </div> <div class="wy-menu wy-menu-vertical" data-spy=affix role=navigation aria-label="main navigation"> <ul> <li class=toctree-l1><a class="reference internal" href=../..>Home</a> </li> </ul> <ul> <li class=toctree-l1><a href=../../publications/ class="reference internal">Publications</a> </li> </ul> <ul> <li class=toctree-l1><a href=../../people/ class="reference internal">People</a> </li> </ul> <ul> <li class=toctree-l1><a href=../../research/ class="reference internal">Research</a> </li> </ul> <p class=caption><span class=caption-text>Courses</span></p> <ul class=current> <li class=toctree-l1><a href=../PSY5036F2019/ class="reference internal">PSY5036F2019</a> </li> <li class=toctree-l1><a href=../PSY8036SP2019/ class="reference internal">PSY8036SP2019</a> </li> <li class=toctree-l1><a href=../PSY5038F2018/ class="reference internal">PSY5038F2018</a> </li> <li class="toctree-l1 current"><a href=./ class="reference internal current">PSY8036SP2018</a> <ul class=current> <li class=toctree-l2><a class="reference internal" href=#background>Background</a> </li> <li class=toctree-l2><a class="reference internal" href=#tentative-syllabus>Tentative Syllabus</a> </li> <li class=toctree-l2><a class="reference internal" href=#sample-readings-under-construction>Sample Readings (under construction)</a> <ul> <li class=toctree-l3><a class="reference internal" href=#background_1>Background</a> </li> <li class=toctree-l3><a class="reference internal" href=#shallow-generative-models-texture-synthesis>Shallow generative models: Texture synthesis</a> </li> <li class=toctree-l3><a class="reference internal" href=#hierarchical-deep-data-driven-generative-models>Hierarchical (deep) data-driven generative models</a> </li> <li class=toctree-l3><a class="reference internal" href=#hypnagogic-imagery>Hypnagogic imagery</a> </li> <li class=toctree-l3><a class="reference internal" href=#dreams>Dreams</a> </li> <li class=toctree-l3><a class="reference internal" href=#hallucinations>Hallucinations</a> </li> <li class=toctree-l3><a class="reference internal" href=#imagery-and-imagination>Imagery and imagination</a> </li> <li class=toctree-l3><a class="reference internal" href=#imagery-and-memory>Imagery and memory</a> </li> </ul> </li> </ul> </li> <li class=toctree-l1><a href=../PSY8036SP2021/ class="reference internal">PSY8036SP2021</a> </li> </ul> <p class=caption><span class=caption-text>Demos</span></p> <ul> <li class=toctree-l1><a href=../../demos/lightness-shape/ class="reference internal">Lightness and Shape</a> </li> <li class=toctree-l1><a href=../../demos/motion-surface/ class="reference internal">Motion and Surface Material</a> </li> <li class=toctree-l1><a href=../../demos/retinotopy/ class="reference internal">Retinotopy</a> </li> <li class=toctree-l1><a href=../../demos/shadows/ class="reference internal">Shadows</a> </li> <li class=toctree-l1><a href=../../demos/transparency/ class="reference internal">Transparency</a> </li> <li class=toctree-l1><a class="reference internal" href=../../images/BlojKerstenHurlbertDemo99.pdf>Color and Mutual Illumination</a> </li> </ul> <p class=caption><span class=caption-text>Data sets</span></p> <ul> <li class=toctree-l1><a href=../../datasets/camouflage/camouflage/ class="reference internal">Camouflage</a> </li> </ul> <ul> <li class=toctree-l1><a href=../../contact/ class="reference internal">Contact</a> </li> </ul> </div> </div> </nav> <section data-toggle=wy-nav-shift class=wy-nav-content-wrap> <nav class=wy-nav-top role=navigation aria-label="top navigation"> <i data-toggle=wy-nav-top class="fa fa-bars"></i> <a href=../..>Computational Vision Lab</a> </nav> <div class=wy-nav-content> <div class=rst-content> <div role=navigation aria-label="breadcrumbs navigation"> <ul class=wy-breadcrumbs> <li><a href=../..>Docs</a> &raquo;</li> <li>Courses &raquo;</li> <li>PSY8036SP2018</li> <li class=wy-breadcrumbs-aside> </li> </ul> <hr> </div> <div role=main> <div class=section> <h1 id=data-driven-generative-models-for-perception-dreaming-and-imagining-psy8036sp2018>Data-driven generative models for perception, dreaming, and imagining <small>PSY8036SP2018</small><a class=headerlink href=#data-driven-generative-models-for-perception-dreaming-and-imagining-psy8036sp2018 title="Permanent link">&para;</a></h1> <p><em>University of Minnesota, Spring Semester, 2018</em></p> <p><strong>Topics in Computational Vision</strong><br> <em>Psy 8036 (Kersten)</em><br> <em>Psy 5993 Section 034 (Schrater)</em> </p> <p><strong>Instructors:</strong><br> Dan Kersten <a href=mailto:kersten@umn.edu>kersten@umn.edu</a><br> Paul Schrater <a href=mailto:schrater@umn.edu>schrater@umn.edu</a> </p> <div class="admonition abstract"> <p class=admonition-title>Abstract</p> <p>It has been proposed that perception is fundamentally a process of “analysis-by-synthesis” in which the sensory input is analyzed bottom-up, with perceptual interpretations tested and refined by top-down predictions of the input, through synthesis. However, while the computational and neural study of the analysis component is well-developed, less is known about the principles and mechanisms that underly synthesis. This seminar will explore recent advances using “deep” learning algorithms to discover hierarchical statistical regularities in large datasets of natural patterns, and the relevance of the learning results to models of human perception and recognition. These algorithms also provide the basis for the stochastic synthesis of novel, yet familiar patterns, which raises the question of whether the human experiences of dreams and hallucinations, and the ability to imagine, reflect the same statistical regularities that are discoverable using machine learning. The class format will include short introductory lectures by the instructors, and weekly student presentations of current literature. The short lectures will provide historical context as well as tutorials on machine learning (e.g. TensorFlow for neural network simulations).</p> </div> <h2 id=background>Background<a class=headerlink href=#background title="Permanent link">&para;</a></h2> <p>There is a long history of theories of perception in which the brain “explains” sensory input in terms of external, behaviorally relevant causes. A current hypothesis is that this process is implemented in part by cortical feedback mechanisms that synthesize predictions of early data representations in order to test how well the brain's current interpretation of the world corresponds with the sensory data. In this view, perception involves a cycle in which the incoming data triggers a set of explanations, i.e. hypotheses, which are used to measure how far the expected sensory input differs from the actual input. From a computational perspective, such generative models of perceptual inference have a number of advantages over strictly bottom-up inference. A generative model can incorporate measures of "goodness-of-fit" to decide whether to accept or reject an interpretation--some explanations are better than others. Discrepancies between sensory data and predictions may also be used to direct attentional resources and signal whether more complex combinations of hypotheses are needed. Further, with sufficient structure, a generative model could provide the basis for the perceptual interpretation of sensory input outside the range of past experience.</p> <p>While computational theories for bottom-up neural mechanisms for perception have received considerable scientific attention, much less is known about top-down mechanisms. This seminar will explore the idea that the brain has hierarchically structured mechanisms that can synthesize patterns of input representations with the following constraints: 1) the mechanisms build on inductive structural biases that are innate; 2) the mechanisms reflect the statistical regularities induced by the physical causes of sensory experience, i.e. they are "data-driven"; 3) the need for cognitive processes to access semantic, perceptual content over levels of abstraction. Assumptions 1) and 2) constrain the class of generative models to be "data-driven", i.e. models that can be learned from sensory data.</p> <p>Recent computational methods for data-driven pattern synthesis (e.g. VAE, InfoGAN, Adversarial Bayes, StackGAN) will be covered in this seminar.  We will also explore the proposal that the same circuitry that may underly feedback in perception is used during imagery, dreams, and hallucinations. </p> <h2 id=tentative-syllabus>Tentative Syllabus<a class=headerlink href=#tentative-syllabus title="Permanent link">&para;</a></h2> <table> <thead> <tr> <th> Week </th> <th> Topics </th> <th>Background material</th> <th>Discussion topics and papers</th> </tr> </thead> <tbody> <tr> <td>1: Jan 16</td> <td>Background<br> Models of perception</td> <td>Yuille, A., &amp; Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301–308.</td> <td> </td> </tr> <tr> <td>2: Jan 23</td> <td>Overview of machine learning</td> <td>Ackley, D. H., Hinton, G. E., &amp; Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147–169.</td> <td> </td> </tr> <tr> <td>3: Jan 30</td> <td>Shallow image models, textures</td> <td>Zhu, S. C., Wu, Y., &amp; Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107–126. McDermott, J. H., Schemitsch, M., &amp; Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493–498.</td> <td>   </td> </tr> <tr> <td>4: Feb 6</td> <td>Hierarchical image models, deep learning</td> <td>Zhu, S.-C., &amp; Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends® in Computer Graphics and Vision, 2(4), 259–362.</td> <td>Topic preview: Visual imagery</td> </tr> <tr> <td>5: Feb 13</td> <td>Hierarchical image models, deep learning</td> <td> </td> <td>Topic preview: Auditory imagery</td> </tr> <tr> <td>6: Feb 20</td> <td>Hierarchical image models, deep learning</td> <td> </td> <td>Topic preview: Hypnagogic imagery</td> </tr> <tr> <td>7: Feb 27</td> <td>Dynamic textures, patterns</td> <td>Xie, J., &amp; Zhu, S. C. (n.d.). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet. arXiv.org. Vondrick, C., Pirsiavash, H., &amp; Torralba, A. (2016). Generating Videos with Scene Dynamics. Advances in Neural Information Processing Systems NIPS, 613–621.</td> <td>Topic preview: Dreams</td> </tr> <tr> <td>8: Mar 6</td> <td>Visual imagery</td> <td>Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., &amp; Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1–15. Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., &amp; Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1–9.</td> <td>Topic preview: Lucid dreaming</td> </tr> <tr> <td>Mar 13</td> <td>Spring Break</td> <td> </td> <td> </td> </tr> <tr> <td>9: Mar 20</td> <td>Auditory, musical imagery</td> <td>Zatorre, R. J., &amp; Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9–12. Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. “Hearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.” Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684–89. McDermott, Josh H., and Andrew J. Oxenham. “Spectral Completion of Partially Masked Sounds.” Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939–5944.</td> <td>Topic overview: Hallucinations &amp; psychedelics</td> </tr> <tr> <td>10: Mar 27</td> <td>Hypnagogic imagery</td> <td>Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin.</td> <td>Topic preview: Hallucinations &amp; schizophrenia</td> </tr> <tr> <td>11: Apr 3</td> <td>Dreams</td> <td>Stickgold, R., Hobson, J. A., Fosse, R., &amp; Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052–1057. Crick, F., G. Mitchison., 1983. The function of dream sleep. Nature. Springer</td> <td>Topic preview: Imagination</td> </tr> <tr> <td>12: Apr 10</td> <td>Lucid dreaming</td> <td>Voss, U., Holzmann, R., Tuin, I., , J. A. Hobson., 2009. Lucid dreaming: a state of consciousness with features of both waking and non-lucid dreaming. Sleep.</td> <td> </td> </tr> <tr> <td>13: Apr 17</td> <td>Hallucinations</td> <td>Seriès, P., Reichert, D. P., &amp; Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020–2028.  Ermentrout, G. B., &amp; Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137–150 Howard, R. J., Brammer, M. J., David, A., Woodruff, P., &amp; Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742.</td> <td> </td> </tr> <tr> <td>14: Apr 24</td> <td>Hallucinations</td> <td>Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., &amp; Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86–97</td> <td> </td> </tr> <tr> <td>15: May 1</td> <td>Imagination, art and design</td> <td>Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., &amp; Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633–2683.</td> <td> </td> </tr> <tr> <td>16: May 8</td> <td>Finals week</td> <td> </td> <td>FINAL PROJECT PRESENTATIONS</td> </tr> </tbody> </table> <h2 id=sample-readings-under-construction>Sample Readings (under construction)<a class=headerlink href=#sample-readings-under-construction title="Permanent link">&para;</a></h2> <h3 id=background_1>Background<a class=headerlink href=#background_1 title="Permanent link">&para;</a></h3> <p>Ackley, D. H., Hinton, G. E., &amp; Sejnowski, T. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9(1), 147–169.<br> Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., &amp; Friston, K. J. (2012). Canonical Microcircuits for Predictive Coding. Neuron, 76(4), 695–711.<br> Berkes, P., Orban, G., Lengyel, M., &amp; Fiser, J. (2011). Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science, 331(6013), 83–87.<br> Dayan, P., Hinton, G. E., Neal, R. M., &amp; Zemel, R. S. (1995). The Helmholtz Machine. Neural Computation, 7(5), 889–904.<br> Ouden, den, H. E. M. (2012). How prediction errors shape perception, attention, and motivation, 1–12.<br> Orban, G., Pietro Berkes, Fiser, J., &amp; Lengyel, M. (2016). Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex. Neuron, 92(2), 530–543.<br> MacKay, D. M. (1956). Towards an information-flow model of human behaviour. British Journal of Psychology (London, England : 1953), 47(1), 30–43.<br> Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332–1338. http://doi.org/10.1126/science.aab3050<br> LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444. http://doi.org/10.1038/nature14539<br> McDermott, Josh H., and Andrew J. Oxenham. “Spectral Completion of Partially Masked Sounds.” Proceedings of the National Academy of Sciences 105, no. 15 (2008): 5939–5944.Mumford, D. (1992). On the computational architecture of the neocortex. Biological Cybernetics, 66(3), 241–251.<br> Mumford, D. (1994). Pattern theory: a unifying perspective, 187–224.<br> Rao, R. P. N., &amp; Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience, 2, 79–87.<br> Tu, Z., Chen, X., Yuille, A. L., &amp; Zhu, S.-C. (2005). Image parsing: Unifying segmentation, detection, and recognition. International Journal of Computer Vision, 63(2), 113–140.<br> Yuille, A., &amp; Kersten, D. (2006). Vision as Bayesian inference: analysis by synthesis? Trends in Cognitive Sciences, 10(7), 301–308.<br> Richards, W. (1971). The Fortification Illusions of Migraines, Scientific American, 1–10.<br> Zhu, S.-C., &amp; Mumford, D. (2006). Quest for a stochastic grammar of images. Foundations and Trends® in Computer Graphics and Vision, 2(4), 259–362. http://doi.org/10.1561/0600000018</p> <h3 id=shallow-generative-models-texture-synthesis>Shallow generative models: Texture synthesis<a class=headerlink href=#shallow-generative-models-texture-synthesis title="Permanent link">&para;</a></h3> <p>Freeman, J., &amp; Simoncelli, E. P. (2011). Metamers of the ventral stream. Nature Publishing Group, 14(9), 1195–1201. http://doi.org/10.1038/nn.2889<br> McDermott, J. H., Schemitsch, M., &amp; Simoncelli, E. P. (2013). Summary statistics in auditory perception. Nature Publishing Group, 16(4), 493–498.<br> McDermott, J. H., &amp; Simoncelli, E. P. (2011). Sound Texture Perception via Statistics of the Auditory Periphery: Evidence from Sound Synthesis. Neuron, 71(5), 926–940.<br> Zhu, S. C., Wu, Y., &amp; Mumford, D. (1998). Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling. International Journal of Computer Vision, 27(2), 107–126.</p> <h3 id=hierarchical-deep-data-driven-generative-models>Hierarchical (deep) data-driven generative models<a class=headerlink href=#hierarchical-deep-data-driven-generative-models title="Permanent link">&para;</a></h3> <p>Chen, X., Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., &amp; Abbeel, P. (2016). InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, 2172–2180.<br> Goodfellow, I. (2016, December 31). NIPS 2016 Tutorial: Generative Adversarial Networks.<br> Kulkarni, T. D., Whitney, W. F., Kohli, P., &amp; Tenenbaum, J. (2015). Deep Convolutional Inverse Graphics Network, 2539–2547.<br> Rock, J., Issaranon, T., Deshpande, A., &amp; Forsyth, D. (2016, December 5). Authoring image decompositions with generative models.<br> Varol, G., Romero, J., Martin, X., Mahmood, N., Black, M. J., Laptev, I., &amp; Schmid, C. (2017, January 5). Learning from Synthetic Humans.<br> Xie, J., Zhu, S.-C., &amp; Wu, Y. N. (2016, June 3). Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet.<br> Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., &amp; Lipson, H. (2015, June 22). Understanding Neural Networks Through Deep Visualization.<br> Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., &amp; Metaxas, D. (2016, December 10). StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks.</p> <h3 id=hypnagogic-imagery>Hypnagogic imagery<a class=headerlink href=#hypnagogic-imagery title="Permanent link">&para;</a></h3> <p>Gurstelle, E. B., &amp; de Oliveira, J. L. (2004). Daytime parahypnagogia: a state of consciousness that occurs when we almost fall asleep. Medical Hypotheses, 62(2), 166–168. http://doi.org/10.1016/S0306-9877(03)00306-2<br> Holmes, E. A., James, E. L., Coode-Bate, T., &amp; Deeprose, C. (2009). Can Playing the Computer Game “Tetris” Reduce the Build-Up of Flashbacks for Trauma? A Proposal from Cognitive Science. PLoS ONE, 4(1), e4153. http://doi.org/10.1371/journal.pone.0004153.t004<br> Nielsen, T. A. (1995). Describing and modeling hypnagogic imagery using a systematic self-observation procedure. Dreaming, 5(2), 75–94. http://doi.org/10.1037/h0094426<br> Nielsen, T. A. (2016). A Self-Observational Study of Spontaneous Hypnagogic Imagery Using the Upright Napping Procedure. Imagination, Cognition and Personality, 11(4), 353–366. http://doi.org/10.2190/3LVV-L5GY-UR5V-N0TG<br> *Schacter, D. L. (1976). The hypnagogic state: a critical review of the literature. Psychological Bulletin.<br> Stickgold, R. (2000). Replaying the Game: Hypnagogic Images in Normals and Amnesics. Science, 290(5490), 350–353. http://doi.org/10.1126/science.290.5490.350</p> <h3 id=dreams>Dreams<a class=headerlink href=#dreams title="Permanent link">&para;</a></h3> <p>Band, J. C. Z. F. A., 2016. (n.d.). Animal “Hypnosis” and Waking Nightmares. Anomalistik.De<br> Crick, F., G. Mitchison., 1983. The function of dream sleep. Nature. Springer<br> *Hobson, J. A., &amp; Mccarley, R. W. (197.). The brain as a dream state generator: an activation-synthesis hypothesis of the dream process. The American Journal of Psychiatry.<br> Dresler, M., Koch, S. P., Wehrle, R., Spoormaker, V. I., Holsboer, F., Steiger, A., et al. (2011). Dreamed Movement Elicits Activation in the Sensorimotor Cortex. Current Biology : CB.<br> Stickgold, R., Hobson, J. A., Fosse, R., &amp; Fosse, M. (2001). Sleep, Learning, and Dreams: Off-line Memory Reprocessing. Science, 294(5544), 1052–1057. http://doi.org/10.1126/science.1063530<br> Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272–1278. http://doi.org/10.1038/nature04286<br> Studies, J. H. J. O. C., 2014. (n.d.). Consciousness, dreams, and inference: the cartesian theatre revisited. Ingentaconnect.com </p> <h3 id=hallucinations>Hallucinations<a class=headerlink href=#hallucinations title="Permanent link">&para;</a></h3> <p>Bressloff, P. C., Cowan, J. D., Golubitsky, M., Thomas, P. J., &amp; Wiener, M. C. (2002). What geometric visual hallucinations tell us about the visual cortex. Neural Computation, 14(3), 473–491. http://doi.org/10.1162/089976602317250861<br> Cummings, J. L., &amp; Miller, B. L. (1987). Visual hallucinations. Clinical occurrence and use in differential diagnosis. The Western Journal of Medicine, 146(1), 46–51.<br> *Ermentrout, G. B., &amp; Cowan, J. D. (1979). A mathematical theory of visual hallucination patterns. Biological Cybernetics, 34(3), 137–150. http://doi.org/10.1007/BF00336965<br> Merabet, L. B., Maguire, D., Warde, A., Alterescu, K., Stickgold, R., &amp; Pascual-Leone, A. (2004). Visual hallucinations during prolonged blindfolding in sighted subjects. Journal of Neuro-Ophthalmology, 24(2), 109–113.<br> Howard, R. J., Brammer, M. J., David, A., Woodruff, P., &amp; Williams, S. (1998). The anatomy of conscious vision: an fMRI study of visual hallucinations. Nature neuroscience, 1(8), 738-742.Seriès, P., Reichert, D. P., &amp; Storkey, A. J. (2010). Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model, 2020–2028.<br> Silverstein, S. M. (2016). Visual Perception Disturbances in Schizophrenia: A Unified Model. In The Neuropsychopathology of Schizophrenia: Molecules, Brain Systems, Motivation, and Cognition (3<sup>rd</sup> ed., Vol. 63, pp. 77–132). Cham: Springer International Publishing. http://doi.org/10.1007/978-3-319-30596-7_4<br> Kumar, S., Sedley, W., Barnes, G. R., Teki, S., Friston, K. J., &amp; Griffiths, T. D. (2014). A brain basis for musical hallucinations. Cortex, 52(C), 86–97. http://doi.org/10.1016/j.cortex.2013.12.002</p> <h3 id=imagery-and-imagination>Imagery and imagination<a class=headerlink href=#imagery-and-imagination title="Permanent link">&para;</a></h3> <p>Chetverikov, A., &amp; Kristjánsson, Á. (2016). On the joys of perceiving: Affect as feedback for perceptual predictions. Actpsy, 169(C), 1–10. http://doi.org/10.1016/j.actpsy.2016.05.005<br> Dijkstra, N., Zeidman, P., Ondobaka, S., Gerven, M. A. J., &amp; Friston, K. (2017). Distinct Top-down and Bottom-up Brain Connectivity During Visual Perception and Imagery. Scientific Reports, 1–9. http://doi.org/10.1038/s41598-017-05888-8<br> Friston, K. J., Lin, M., Frith, C. D., Pezzulo, G., Hobson, J. A., &amp; Ondobaka, S. (2017). Active Inference, Curiosity and Insight. Neural Computation, 29(10), 2633–2683. http://doi.org/10.1162/neco_a_00999<br> Kosslyn, S. M., &amp; Thompson, W. L. (2003). When is early visual cortex activated during visual mental imagery? Psychological Bulletin, 129(5), 723–746. http://doi.org/10.1037/0033-2909.129.5.723<br> Kosslyn, S. M., Alpert, N. M., Thompson, W. L., Maljkovic, V., Weise, S. B., Chabris, C. F., et al. (1993). Visual Mental Imagery Activates Topographically Organized Visual Cortex: PET Investigations. Journal of Cognitive Neuroscience, 5(3), 263–287. http://doi.org/10.1162/jocn.1993.5.3.263<br> Kosslyn, S., &amp; Ganis, G. (2000). Neural foundations of imagery. Nature Reviews ….<br> Pearson, J., Naselaris, T., Holmes, E. A., &amp; Kosslyn, S. M. (2015). Mental Imagery: Functional Mechanisms and Clinical Applications. Trends in Cognitive Sciences, 19(10), 590–602. http://doi.org/10.1016/j.tics.2015.08.003<br> Riecke, L., A. J. van Opstal, R. Goebel, and E. Formisano. “Hearing Illusory Sounds in Noise: Sensory-Perceptual Transformations in Primary Auditory Cortex.” Journal of Neuroscience 27, no. 46 (November 14, 2007): 12684–89. https://doi.org/10.1523/JNEUROSCI.2713-07.2007.<br> Schacter, D. L., Addis, D. R., Hassabis, D., Martin, V. C., Spreng, R. N., &amp; Szpunar, K. K. (2012). The Future of Memory: Remembering, Imagining, and the Brain. Neuron, 76(4), 677–694. http://doi.org/10.1016/j.neuron.2012.11.001<br> Zatorre, R. J., &amp; Halpern, A. R. (2005). Mental Concerts: Musical Imagery and Auditory Cortex. Neuron, 47(1), 9–12. http://doi.org/10.1016/j.neuron.2005.06.013</p> <h3 id=imagery-and-memory>Imagery and memory<a class=headerlink href=#imagery-and-memory title="Permanent link">&para;</a></h3> <p>Albers, A. M., Kok, P., Toni, I., Dijkerman, H. C., &amp; de Lange, F. P. (2013). Shared Representations for Working Memory and Mental Imagery in Early Visual Cortex. Curbio, 23(15), 1427–1431. http://doi.org/10.1016/j.cub.2013.05.065<br> Christophel, T. B., Klink, P. C., Spitzer, B., Roelfsema, P. R., &amp; Haynes, J.-D. (2017). The Distributed Nature of Working Memory. Trends in Cognitive Sciences, 1–15. http://doi.org/10.1016/j.tics.2016.12.007<br> Naselaris, T., Olman, C. A., Stansbury, D. E., Ugurbil, K., &amp; Gallant, J. L. (2015). A voxel-wise encoding model for early visual areas decodes mental images of remembered scenes. NeuroImage, 105(C), 215–228. http://doi.org/10.1016/j.neuroimage.2014.10.018<br> Self, M. W., van Kerkoerle, T., &amp; Roelfsema, P. R. (2016). Layer-specificity in the effects of attention and working memory on activity in primary visual cortex. Nature Communications, 8, 1–12. http://doi.org/10.1038/ncomms13804<br> Stickgold, R. (2005). Sleep-dependent memory consolidation. Nature, 437(7063), 1272–1278. http://doi.org/10.1038/nature04286</p> </div> </div> <footer> <div class=rst-footer-buttons role=navigation aria-label="footer navigation"> <a href=../PSY8036SP2021/ class="btn btn-neutral float-right" title=PSY8036SP2021>Next <span class="icon icon-circle-arrow-right"></span></a> <a href=../PSY5038F2018/ class="btn btn-neutral" title=PSY5038F2018><span class="icon icon-circle-arrow-left"></span> Previous</a> </div> <hr> <div role=contentinfo> <!-- Copyright etc --> </div> Built with <a href=https://www.mkdocs.org/ >MkDocs</a> using a <a href=https://github.com/snide/sphinx_rtd_theme>theme</a> provided by <a href=https://readthedocs.org>Read the Docs</a>. </footer> </div> </div> </section> </div> <div class=rst-versions role=note aria-label=versions> <span class=rst-current-version data-toggle=rst-current-version> <span><a href=../PSY5038F2018/ style="color: #fcfcfc;">&laquo; Previous</a></span> <span style="margin-left: 15px"><a href=../PSY8036SP2021/ style="color: #fcfcfc">Next &raquo;</a></span> </span> </div> <script>var base_url = '../..';</script> <script src=../../js/theme.js defer></script> <script src=../../search/main.js defer></script> <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script> </body> </html> 