<!DOCTYPE html><!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]--><!--[if gt IE 8]><!--><html class=no-js lang=en> <!--<![endif]--> <head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=author content="Daniel Kersten"><link rel="shortcut icon" href=../img/favicon.ico><title>Research - Computational Vision Lab</title><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700"><link rel=stylesheet href=../css/theme.css><link rel=stylesheet href=../css/theme_extra.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css><script>
    // Current page data
    var mkdocs_page_name = "Research";
    var mkdocs_page_input_path = "research.md";
    var mkdocs_page_url = null;
  </script><script src=../js/jquery-2.1.1.min.js defer></script><script src=../js/modernizr-2.8.3.min.js defer></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script></head> <body class=wy-body-for-nav role=document> <div class=wy-grid-for-nav> <nav data-toggle=wy-nav-shift class="wy-nav-side stickynav"> <div class=wy-side-scroll> <div class=wy-side-nav-search> <a href=.. class="icon icon-home"> Computational Vision Lab</a> <div role=search> <form id=rtd-search-form class=wy-form action=../search.html method=get> <input type=text name=q placeholder="Search docs" title="Type search term here"> </form> </div> </div> <div class="wy-menu wy-menu-vertical" data-spy=affix role=navigation aria-label="main navigation"> <ul> <li class=toctree-l1><a class="reference internal" href=..>Home</a> </li> </ul> <ul> <li class=toctree-l1><a href=../publications/ class="reference internal">Publications</a> </li> </ul> <ul> <li class=toctree-l1><a href=../people/ class="reference internal">People</a> </li> </ul> <ul class=current> <li class="toctree-l1 current"><a href=./ class="reference internal current">Research</a> <ul class=current> <li class=toctree-l2><a class="reference internal" href=#approach>Approach</a> <ul> <li class=toctree-l3><a class="reference internal" href=#methodologies>Methodologies</a> </li> <li class=toctree-l3><a class="reference internal" href=#topics-of-interest>Topics of interest</a> </li> <li class=toctree-l3><a class="reference internal" href=#phenomena-of-interest>Phenomena of interest</a> </li> <li class=toctree-l3><a class="reference internal" href=#theory-and-computation>Theory and computation</a> </li> </ul> </li> <li class=toctree-l2><a class="reference internal" href=#innovation>Innovation</a> <ul> <li class=toctree-l3><a class="reference internal" href=#vision-as-statistical-inference-bayesian-approaches>Vision as statistical inference Bayesian approaches</a> </li> </ul> </li> </ul> </li> </ul> <p class=caption><span class=caption-text>Courses</span></p> <ul> <li class=toctree-l1><a href=../courses/PSY5036F2019/ class="reference internal">PSY5036F2019</a> </li> <li class=toctree-l1><a href=../courses/PSY8036SP2019/ class="reference internal">PSY8036SP2019</a> </li> <li class=toctree-l1><a href=../courses/PSY5038F2018/ class="reference internal">PSY5038F2018</a> </li> <li class=toctree-l1><a href=../courses/PSY8036SP2018/ class="reference internal">PSY8036SP2018</a> </li> <li class=toctree-l1><a href=../courses/PSY8036SP2021/ class="reference internal">PSY8036SP2021</a> </li> </ul> <p class=caption><span class=caption-text>Demos</span></p> <ul> <li class=toctree-l1><a href=../demos/lightness-shape/ class="reference internal">Lightness and Shape</a> </li> <li class=toctree-l1><a href=../demos/motion-surface/ class="reference internal">Motion and Surface Material</a> </li> <li class=toctree-l1><a href=../demos/retinotopy/ class="reference internal">Retinotopy</a> </li> <li class=toctree-l1><a href=../demos/shadows/ class="reference internal">Shadows</a> </li> <li class=toctree-l1><a href=../demos/transparency/ class="reference internal">Transparency</a> </li> <li class=toctree-l1><a class="reference internal" href=../images/BlojKerstenHurlbertDemo99.pdf>Color and Mutual Illumination</a> </li> </ul> <p class=caption><span class=caption-text>Data sets</span></p> <ul> <li class=toctree-l1><a href=../datasets/camouflage/camouflage/ class="reference internal">Camouflage</a> </li> </ul> <ul> <li class=toctree-l1><a href=../contact/ class="reference internal">Contact</a> </li> </ul> </div> </div> </nav> <section data-toggle=wy-nav-shift class=wy-nav-content-wrap> <nav class=wy-nav-top role=navigation aria-label="top navigation"> <i data-toggle=wy-nav-top class="fa fa-bars"></i> <a href=..>Computational Vision Lab</a> </nav> <div class=wy-nav-content> <div class=rst-content> <div role=navigation aria-label="breadcrumbs navigation"> <ul class=wy-breadcrumbs> <li><a href=..>Docs</a> &raquo;</li> <li>Research</li> <li class=wy-breadcrumbs-aside> </li> </ul> <hr> </div> <div role=main> <div class=section> <h1 id=research>Research<a class=headerlink href=#research title="Permanent link">&para;</a></h1> <div class="admonition highlights"> <p>The Computational Vision Lab combines computational theory with behavioral and brain image experiments to understand how we see the world around us.</p> </div> <p>Vision is used for recognition, planning and motor actions. Exactly how to get from the retinal image intensities to useful actions is a tough problem requiring multiple approaches. A major theoretical challenge is to discover the computational principles required to infer world properties and determine motor output from images. Computational vision searches for these solutions. The empirical challenge is to discover how our visual systems and those of other animals are built to achieve useful actions from the images received.</p> <h2 id=approach>Approach<a class=headerlink href=#approach title="Permanent link">&para;</a></h2> <p>Our research uses computational, psychophysical, and brain imaging approaches to investigate how the visual pathways of the brain transform image information into useful plans and action.</p> <h3 id=methodologies>Methodologies<a class=headerlink href=#methodologies title="Permanent link">&para;</a></h3> <ul> <li>psychophysics</li> <li>brain imaging (fMRI)</li> <li>neurophysiology</li> <li>computational modeling</li> <li>machine learning and computer vision</li> <li>theoretical neuroscience</li> </ul> <h3 id=topics-of-interest>Topics of interest<a class=headerlink href=#topics-of-interest title="Permanent link">&para;</a></h3> <ul> <li>perceptual inference</li> <li>perceptual organization</li> <li>object perception</li> <li>perceptual learning</li> <li>vision and action</li> <li>cue integration</li> <li>cortical processing<ul> <li>top-down (feedback) and bottom-up (feed-forward) interaction</li> <li>inhibition</li> <li>suppression</li> <li>adaptation</li> </ul> </li> </ul> <h3 id=phenomena-of-interest>Phenomena of interest<a class=headerlink href=#phenomena-of-interest title="Permanent link">&para;</a></h3> <ul> <li>natural scenes</li> <li>context effects</li> <li>illusion</li> <li>aftereffects</li> <li>shape, size, surface reflectance</li> <li>color</li> <li>motion</li> <li>occlusion, crowding, clutter</li> <li>shadow</li> <li>camouflage</li> </ul> <h3 id=theory-and-computation>Theory and computation<a class=headerlink href=#theory-and-computation title="Permanent link">&para;</a></h3> <ul> <li>statistical (Bayesian) inference[@yuille2006vision]</li> <li>ideal observer models</li> <li>analysis by synthesis</li> <li>predictive coding</li> <li>neural networks</li> <li>hierarchical generative models</li> </ul> <h2 id=innovation>Innovation<a class=headerlink href=#innovation title="Permanent link">&para;</a></h2> <h3 id=vision-as-statistical-inference-bayesian-approaches>Vision as statistical inference <small>Bayesian approaches</small><a class=headerlink href=#vision-as-statistical-inference-bayesian-approaches title="Permanent link">&para;</a></h3> <p>Bayesian approaches have enjoyed a great deal of recent success in their application to problems in computer vision. This success has led to an emerging interest in applying Bayesian methods to modeling human visual perception.</p> <p>We consider the implications of a Bayesian view of visual information processing for experimentally investigating human visual perception. We have outlined the elements of a general program of empirical research which results from taking the basic Bayesian formulation seriously not only as a means for objectively modeling image information through ideal observer analysis (e.g. see our work in object recognition), but also as a framework for characterizing human perceptual inference. A major advantage of following such a program is that, because its structure is the same as that of the Bayesian framework for computational modeling, it supports a strong integration of psychophysics and computational theory. In particular, it provides the foundation for a psychophysics of constraints in which one tests hypotheses regarding quantitative and qualitative constraints used in human perceptual inferences. The Bayesian approach also suggests new ways to conceptualize the general problem of perception and to decompose it into isolable parts for psychophysical investigation; that is, it not only provides a framework for modeling solutions to specific perceptual problems; it also guides the definition of the problems.</p> <div class="admonition figure"> <p class=admonition-title>Analysis by synthesis</p> <p><img alt="Yuille and Kersten 2006 Figure 2" src=../images/YuilleKersten2006F2.jpg></p> <p>Analysis by synthesis. <strong>(a)</strong> Low-level processing can extract edge features, such as bars, and use conjunctions of these features to make bottom-up proposals to access the higher-level models of objects. <strong>(b)</strong> The high-level objects access the image top-down to validate or reject the bottom-up proposals. In this example, the low-level cues propose that the image can be interpreted as an E, an F, or a set of parallel bars. But interpreting it as an F explains almost all the features in the image and is preferred.[@yuille2006vision]</p> </div> </div> </div> <footer> <div class=rst-footer-buttons role=navigation aria-label="footer navigation"> <a href=../courses/PSY5036F2019/ class="btn btn-neutral float-right" title=PSY5036F2019>Next <span class="icon icon-circle-arrow-right"></span></a> <a href=../people/ class="btn btn-neutral" title=People><span class="icon icon-circle-arrow-left"></span> Previous</a> </div> <hr> <div role=contentinfo> <!-- Copyright etc --> </div> Built with <a href=https://www.mkdocs.org/ >MkDocs</a> using a <a href=https://github.com/snide/sphinx_rtd_theme>theme</a> provided by <a href=https://readthedocs.org>Read the Docs</a>. </footer> </div> </div> </section> </div> <div class=rst-versions role=note aria-label=versions> <span class=rst-current-version data-toggle=rst-current-version> <span><a href=../people/ style="color: #fcfcfc;">&laquo; Previous</a></span> <span style="margin-left: 15px"><a href=../courses/PSY5036F2019/ style="color: #fcfcfc">Next &raquo;</a></span> </span> </div> <script>var base_url = '..';</script> <script src=../js/theme.js defer></script> <script src=../search/main.js defer></script> <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script> </body> </html> 