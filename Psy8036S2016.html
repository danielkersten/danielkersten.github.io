<HTML>
<HEAD>
  <META NAME="GENERATOR" CONTENT="Adobe PageMill 2.0 Mac">
  <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=ISO-8859-1">
  <TITLE>Computational Vision</TITLE>
<style type="text/css">
<!--
.style6 {font-size: large; font-weight: bold; }
-->
</style>
</HEAD>
<BODY BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#551a8b" ALINK="#0000ff">
<h3 ALIGN=CENTER>Topics in Computational Vision:</h3>
<h2 ALIGN=CENTER>Person Perception</h2>
<H3 ALIGN=CENTER>University of Minnesota, Spring Semester, 2016</H3>
<H3 ALIGN=CENTER>Psy 8036 (58390)<br>
  <br>
<font size=-1><a href="http://courses.kersten.org">http://courses.kersten.org</a></font><BR>
</H3>
<p><strong>Instructor:</strong> Dan Kersten (kersten@umn.edu)<br>
  <br>
While computer vision has made substantial progress in the development of algorithms for limited visual tasks, achieving human-like visual capabilities remains a stiff challenge. And while there has also been substantial empirical progress in understanding human vision and its relation to brain activity, we do not yet understand the brain&rsquo;s algorithms underlying image interpretation. This seminar will examine the proposal that human vision achieves its high degree of competence through built-in generative knowledge of how world structure causes images. Generative knowledge provides the basis for rapid learning from a relatively small number of examples, and the flexibilty to interpret almost any image.</p>
<p>	There may be no better example of built-in knowledge than our ability to recognize and interpret images of other people, including their  facial expressions, body poses, actions, and intentions. The human visual system can deal with an unlimited range of poses both static and in time, and with large uncertainty in the resulting  local patterns of retinal intensities. Gunnar Johansson's classic &quot;point light walker&quot; movies demonstrate our extraordinary competency at interpreting human actions and interactions from locally ambiguous measurements. </p>
<p>This seminar will examine the role of generative models in person perception addressing questions such as: How can information about faces and body form be represented as compositions of parts? Is there a visual grammar for poses and actions? How is local intensity information integrated to infer body pose, given enormous variability in appearance (e.g. clothing and occlusion by other people)? Is there  task prioritization, where for example, animacy is detected first? How is visual information about body pose represented in the brain?  The class format will consist of short lectures to provide overviews of upcoming themes together with discussion of journal articles led by seminar participants.</p>
<p><br>
  <font color="#660033"><b><font color="#FF0033">Meeting time</font></b></font><font color="#FF0033">:</font> First meeting Tuesday, Jan 19th, 3:00 pm. Regular time to be decided. <BR>
  <B><font color="#FF0033">Place:</font> Elliott Hall S204</B><strong></strong><br>
</p>
<hr align=LEFT>
<h1 align="center"><strong><em>Schedule and Readings (under construction)</em></strong></h1>
<P>
<table width="876" border="1">
  <tr>
    <td width="41"><div align="center"><strong>Week</strong></div></td>
    <td width="107"><div align="center"><strong>Topics</strong></div></td>
    <td width="384"><strong>Background material &amp; sample readings</strong></td>
    <td width="316"><strong>Discussion papers</strong></td>
  </tr>
  <tr>
    <td>1</td>
    <td><div align="center">
      <p><strong>Introduction: The generative approach to integrating local cues with global form</strong></p>
      <p>Discriminative vs. generative models </p>
    </div></td>
    <td>&nbsp;</td>
    <td><p>&nbsp;</p>
<p></p></td>
  </tr>
  <tr>
    <td>2. </td>
    <td><strong>Perception: faces &amp; expressions: What have we learned?</strong> I</td>
    <td><p>&nbsp;</p>
<p>Webster, M. A., &amp; MacLeod, D. I. A. (2011). Visual adaptation and face perception. Philosophical Transactions of the Royal Society B: Biological Sciences, 366(1571), 1702&ndash;1725. http://doi.org/10.1098/rsbl.2006.0440</p>
    <p>&nbsp;</p></td>
    <td><p>Leopold, D. A., O'Toole, A. J., Vetter, T., &amp; Blanz, V. (2001). Prototype-referenced shape encoding revealed by high-level aftereffects. Nature Neuroscience, 4(1), 89&ndash;94. doi:10.1038/82947 <a href="http://www.nature.com/neuro/journal/v4/n1/pdf/nn0101_89.pdf">(pdf)</a></p>
    <p>Fang, F., &amp; He, S. (2005). Viewer-Centered Object Representation in the Human Visual System Revealed by Viewpoint Aftereffects. Neuron, 45(5), 793&ndash;800. <a href="http://ac.els-cdn.com/S0896627305000759/1-s2.0-S0896627305000759-main.pdf?_tid=5f523f3e-bfa7-11e5-8ffd-00000aab0f01&acdnat=1453316308_42343bf1660d974a011cc4c989fa1959">(pdf</a>)</p></td>
  </tr>
  <tr>
    <td>3.</td>
    <td><div align="center">
      <p><strong>Perception: faces &amp; expressions: What have we learned?</strong> II</p>
      <p>&nbsp;</p>
      <p>&nbsp;</p>
    </div></td>
    <td><p>&nbsp;</p>
<p>Cunningham, D. W., Kleiner, M., B&uuml;lthoff, H. H., &amp; Wallraven, C. (2004). The components of conversational facial expressions. APGV '04 Proceedings of the 1st Symposium on Applied perception in graphics and visualization, 143-150 .</p>
<p>&nbsp;</p>
<p>Curio, C., B&uuml;lthoff, H. H., Giese, M. A., &amp; Poggio, T. A. (2010). Dynamic Faces: Insights from Experiments and Computation. Cambridge, MA, USA: MIT Press.</p>
<p>Yu, H., Garrod, O. G. B., &amp; Schyns, P. G. (2012). Perception-driven facial expression synthesis. Computers &amp; Graphics, 36(3), 152&ndash;162. http://doi.org/10.1016/j.cag.2011.12.002</p>
      <p>&nbsp;</p>
    <p>&nbsp;</p></td>
    <td><p>Xu, H., Dayan, P., Lipkin, R. M., &amp; Qian, N. (2008). Adaptation across the cortical hierarchy: Low-level curve adaptation affects high-level facial-expression judgments. Journal of Neuroscience, 28(13), 3374&ndash;3383. (<a href="http://www.jneurosci.org/content/28/13/3374.short">pdf</a>)</p>
      <p>Jack, R. E., Garrod, O. G. B., &amp; Schyns, P. G. (2014). Dynamic Facial Expressions of Emotion Transmit an Evolving Hierarchy of Signals over Time. Curbio, 24(2), 187&ndash;192. <a href="http://www.sciencedirect.com/science/article/pii/S0960982213015194">(pdf</a>)</p>
  <p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>4.</td>
    <td><div align="center"><strong>Perception: human pose &amp; actions I</strong></div></td>
    <td><p>&nbsp;</p>
<p>Blake, R., &amp; Shiffrar, M. (2007). Perception of Human Motion. Annual Review of Psychology, 58(1), 47&ndash;73. (<a href="http://www.annualreviews.org/doi/abs/10.1146/annurev.psych.57.102904.190152">link</a>) </p>
    <p>&nbsp;</p></td>
    <td><p>Troje, N. F. (2002). Decomposing biological motion: A framework for analysis and synthesis of human gait patterns. Journal of Vision, 2(5). (<a href="http://jov.arvojournals.org/article.aspx?articleid=2192503">link</a>)</p>
    <p>Mayer, K. M., Vuong, Q. C., &amp; Thornton, I. M. (2015). Do People &ldquo;Pop Out?&rdquo; PLoS ONE, 10(10), e0139618&ndash;15. (<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0139618">link</a>)</p></td>
  </tr>
  <tr>
    <td>5. </td>
    <td><strong>Perception: human pose &amp; actions II</strong></td>
    <td><p>Kersten, Masmassian, P., &amp; Yuille, A. (2004). Object perception as Bayesian inference. Annual Review of Psychology, 55, 271&ndash;304. http://doi.org/10.1146/annurev.psych.55.090902.142005 (<a href="http://www.annualreviews.org/doi/abs/10.1146/annurev.psych.55.090902.142005">link)</a><br>
      </p>
<p>&nbsp;</p></td>
    <td><p>Hahn, C. A., O'Toole, A. J., &amp; Phillips, P. J. (2015). Dissecting the time course of person recognition in natural viewing environments. British Journal of Psychology (London, England : 1953). http://doi.org/10.1111/bjop.12125 (<a href="http://onlinelibrary.wiley.com/doi/10.1111/bjop.12125/abstract">link</a>)</p>
      <p>Clifford, C. W. G., Mareschal, I., Otsuka, Y., &amp; Watson, T. L. (2015). A Bayesian approach to person perception. Consciousness and Cognition, 36, 406&ndash;413. http://doi.org/10.1016/j.concog.2015.03.015 (<a href="http://www.sciencedirect.com/science/article/pii/S1053810015000719">link</a>)</p>
      <p>&nbsp;</p>
    <p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>6. </td>
    <td><div align="center">
      <p><strong>Computation: face recognition</strong></p>
      <p> Static and dynamic generative models<br>
        The problems of skin, hair.</p>
    </div></td>
    <td><p>The Digital Emily project.<br>
      <a href="http://gl.ict.usc.edu/Research/DigitalEmily/">http://gl.ict.usc.edu/Research/DigitalEmily/</a></p>
<p>Alexander, O., Rogers, M., &amp; Lambeth, W. (2009). Creating a photoreal digital actor: The digital emily project.http://doi.org/10.1109/CVMP.2009.293      (<a href="http://dl.acm.org/citation.cfm?doid=2503385.2503387">link</a>)      </p>
<p>Koenderink, J., &amp; Pont, S. (2003). The secret of velvety skin. Machine Vision and Applications, 14(4), 260&ndash;268. http://doi.org/10.1007/s00138-002-0089-7</p>
      <p>Jones, B. (2006). Approximating the Appearance of Human Skin in Computer Graphics.</p>
      <p>Wang, N., &amp; Ai, H. (2011). A compositional exemplar-based model for hair segmentation. Computer Vision&ndash;ACCV 2010.</p>
      <p>Weyrich, T., Matusik, W., Pfister, H., Bickel, B., Donner, C., Tu, C., et al. (2006). Analysis of human faces using a measurement-based skin reflectance model. ACM Transactions on Graphics (TOG) (Vol. 25, pp. 1013&ndash;1024). ACM. http://doi.org/10.1145/1141911.1141987</p>
<p>Dana, K. J., van Ginneken, B., Nayar, S. K., &amp; Koenderink, J. J. (1999). Reflectance and texture of real-world surfaces. ACM Transactions on Graphics (TOG), 18(1), 1&ndash;34. http://doi.org/10.1145/300776.300778</p>
<p>&nbsp;</p></td>
    <td><p>Ghosh, A., Hawkins, T., Peers, P., Frederiksen, S., &amp; Debevec, P. (2008). Practical modeling and acquisition of layered facial reflectance. ACM Transactions on Graphics, 27(5), 1&ndash;10. http://doi.org/10.1145/1409060.1409092 (<a href="http://dl.acm.org/citation.cfm?id=1409092">link</a>)</p>
      <p>&nbsp;</p>
      <p>Ward, K., Bertails, F., Kim, T.-Y., Marschner, S. R., Cani, M.-P., &amp; Lin, M. C. (2007). A survey on hair modeling: styling, simulation, and rendering. Visualization and Computer Graphics, IEEE Transactions on, 13(2), 213&ndash;234. http://doi.org/10.1109/TVCG.2007.30. <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4069232&tag=1">(link</a>)</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>7. </td>
    <td><div align="center">
      <p><strong>Computation: human form, actions </strong></p>
      <p> The problems of real images. Clutter, multiple people, clothes variation</p>
    </div></td>
    <td><p>Andriluka, M., Roth, S., &amp; Schiele, B. (2009). Pictorial Structures Revisited: People Detection and Articulated Pose Estimation (pp. 1&ndash;8). Presented at the Computer Vision and Pattern Recognition, 2009. (<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206754&tag=1">link</a>)
      </p>
      <p>Felzenszwalb, P. F., &amp; Huttenlocher, D. P. (2005). Pictorial Structures for Object Recognition. International Journal of Computer Vision, 61(1), 55&ndash;79. http://doi.org/10.1023/B:VISI.0000042934.15159.49</p>
      <p>Bourdev, L., &amp; Malik, J. (2009). Poselets: Body part detectors trained using 3D human pose annotations. 2009 IEEE 12th International Conference on Computer Vision (ICCV), 1365&ndash;1372. http://doi.org/10.1109/ICCV.2009.5459303</p>
      <p>Bergou, M., Audoly, B., Vouga, E., Wardetzky, M., Grinspun, E., Bergou, M., et al. (2010). Example-based wrinkle synthesis for clothing animation. ACM Transactions on Graphics (TOG), 29(4), 107. doi:10.1145/1833349.1778844</p>
      <p>Zhu, S., &amp; Mok, P. Y. (2015). Predicting Realistic and Precise Human Body Models Under Clothing Based on Orthogonal-view Photos. Procedia Manufacturing, 3(C), 3812&ndash;3819. </p></td>
    <td><p>Toshev, A., &amp; Szegedy, C. (2014). DeepPose: Human Pose Estimation via Deep Neural Networks, CVPR2014, 1653&ndash;1660. (<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Toshev_DeepPose_Human_Pose_2014_CVPR_paper.pdf">link</a>)</p>
      <p>&nbsp;</p>
      <p>X. Chen and A.L. Yuille. Articulated Pose Estimation with Image-Dependent Preference on Pairwise Relations. NIPS 2014. (<a href="http://papers.nips.cc/paper/5291-articulated-pose-estimation-by-a-graphical-model-with-image-dependent-pairwise-relations">link</a>)</p>
      <p>&nbsp;</p>
    <p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>8. </td>
    <td><div align="center">Spring Break</div></td>
    <td>&nbsp;</td>
    <td><p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td><div align="center"><strong>Compositional models: learning &amp; inference</strong></div></td>
    <td><p>&nbsp;</p>
<p>&nbsp;</p>
      <p>Jin, Y., &amp; Geman, S. (2006). Context and hierarchy in a probabilistic image model. Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, 2, 2145&ndash;2152. </p>
      <p>Zhu, L., Chen, Y., &amp; Yuille, A. (2011). Recursive Compositional Models for Vision: Description and Review of Recent Work. Journal of Mathematical Imaging and Vision, 41(1-2), 122&ndash;146. </p>
      <p>Bienenstock, E., &amp; Geman, S. (1997). Compositionality, MDL priors, and object recognition. Advances in Neural Information Processing Systems, 838&ndash;844.      </p>
      <p>Doumas, L. A. A., &amp; Hummel, J. E. (2010). A computational account of the development of the generalization of shape information. Cognitive Science, 34(4), 698&ndash;712. (<a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1551-6709.2010.01103.x/full">link</a>)</p>
      <p><br>
        <br>
      </p></td>
    <td><p>Tervo, D. G. R., Tenenbaum, J. B., &amp; Gershman, S. J. (2016). Toward the neural implementation of structure learning. Current Opinion in Neurobiology, 37, 99&ndash;105. http://doi.org/10.1016/j.conb.2016.01.014 <br>
      (<a href="http://www.sciencedirect.com/science/article/pii/S095943881600026X">link</a>) </p>
      <p>Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332&ndash;1338. http://doi.org/10.1126/science.aab3050 (<a href="http://science.sciencemag.org/content/350/6266/1332.full">link</a>) </p>
      <p>Gershman, S. J., Tenenbaum, J. B., &amp; Jakel, F. (2015). Discovering hierarchical motion structure. Vision Research, 1&ndash;10. http://doi.org/10.1016/j.visres.2015.03.004<br>
      (<a href="http://www.sciencedirect.com/science/article/pii/S0042698915000814">link</a>) </p>
<p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>9. </td>
    <td><div align="center"><strong>Cortical responses: faces</strong></div></td>
    <td><p>Kanwisher, N., &amp; Dilks, D. D. (2012). The Functional Organization of the Ventral Visual Pathway in Humans (pp. 1&ndash;25).</p>
      <p>Tsao, D. Y., &amp; Livingstone, M. S. (2008). Mechanisms of Face Perception. Annual Review of Neuroscience, 31(1), 411&ndash;437. </p>
      <p>Ohayon, S., Freiwald, W. A., &amp; Tsao, D. Y. (2012). What Makes a Cell Face Selective? The Importance of Contrast. Neuron, 74(3), 567&ndash;581. </p>
      <p>Mende-Siedlecki, P., Verosky, S. C., Turk-Browne, N. B., &amp; Todorov, A. (2013). Robust Selectivity for Faces in the Human Amygdala in the Absence of Expressions. Journal of Cognitive Neuroscience, 25(12), 2086&ndash;2106. </p>
      <p>Furl, N., van Rijsbergen, N. J., Treves, A., Friston, K. J., &amp; Dolan, R. J. (2007). Experience-Dependent Coding of Facial Expression in Superior Temporal Sulcus. Proceedings of the National Academy of Sciences of the United States of America, 104(33), 13485&ndash;13489.</p>
      <p>Dubois, J., de Berker, A. O., &amp; Tsao, D. Y. (2015). Single-Unit Recordings in the Macaque Face Patch System Reveal Limitations of fMRI MVPA. Journal of Neuroscience, 35(6), 2791&ndash;2802. http://doi.org/10.1523/JNEUROSCI.4037-14.2015<br>
      </p>
    <p>&nbsp;</p></td>
    <td><p>Meyers, E. M., Borzello, M., Freiwald, W. A., &amp; Tsao, D. (2015). Intelligent Information Loss: The Coding of Facial Identity, Head Pose, and Non-Face Information in the Macaque Face Patch System. The Journal of Neuroscience, 35(18), 7069&ndash;7081. <a href="http://doi.org/10.1523/JNEUROSCI.3086-14.2015">http://doi.org/10.1523/JNEUROSCI.3086-14.2015</a></p></td>
  </tr>
  <tr>
    <td>10.</td>
    <td><p align="center"><strong>Cortical responses: bodies I</strong></p></td>
    <td><p>&nbsp;</p>
      <p>Downing, P. E., &amp; Peelen, M. V. (2011). The role of occipitotemporal body-selective regions in person perception. Cognitive Neuroscience, 2(3-4), 186&ndash;203. </p>
      <p>van Koningsbruggen, M. G., Peelen, M. V., &amp; Downing, P. E. (2013). A Causal Role for the Extrastriate Body Area in Detecting People in Real-World Scenes. Journal of Neuroscience, 33(16), 7003&ndash;7010. </p>
      <p>Orlov, T., Makin, T. R., &amp; Zohary, E. (2010). Topographic Representation of the Human Body in the Occipitotemporal Cortex. Neuron, 68(3), 586&ndash;600. <br>
      </p>
      <p>&nbsp;</p></td>
    <td><p>&nbsp;</p>
    <p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>11. </td>
    <td><strong>Cortical responses: bodies I</strong>I</td>
    <td><p>Jastorff, J., Popivanov, I. D., Vogels, R., Vanduffel, W., &amp; Orban, G. A. (2012). Integration of shape and motion cues in biological motion processing in the monkey STS. NeuroImage, 60(2), 911&ndash;921. http://doi.org/10.1016/j.neuroimage.2011.12.087</p>
      <p>Weiner, K. S., &amp; Grill-Spector, K. (2011). Neural representations of faces and limbs neighbor in human high-level visual cortex: evidence for a new organization principle. Psychological Research, 77(1), 74&ndash;97. </p></td>
    <td><p>&nbsp;</p>
    <p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>12.</td>
    <td><div align="center"><strong>Social interactions I</strong></div></td>
    <td><p>Heidel and Simmel<br>
    </p></td>
    <td><p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>13.</td>
    <td><div align="center"><strong>Social interactions II</strong></div></td>
    <td>SEBANZ, N., BEKKERING, H., &amp; KNOBLICH, G. (2006). Joint action: bodies and minds moving together. Trends in Cognitive Sciences, 10(2), 70&ndash;76. </td>
    <td><p>&nbsp;</p>
      <p>&nbsp;</p>
      <p>&nbsp;</p>
    <p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>14.</td>
    <td><strong>Task hierarchies: Detecting animacy</strong></td>
    <td><p>Scholl, B., &amp; Tremoulet, P. (2000). Perceptual causality and animacy. Trends in Cognitive Sciences, 4(8), 299&ndash;309.</p>
      <p>Myers. (2003). The Detection of Contingency and Animacy from Simple Animations in the Human Brain, 1&ndash;8.</p>
      <p>Scholl, B. J., &amp; Gao, T. (2013). Perceiving animacy and intentionality: Visual processing or higher-level judgment. Social Perception: Detection and &hellip;. </p>
      <p>Pitcher, D., Goldhaber, T., Duchaine, B., Walsh, V., &amp; Kanwisher, N. (2012). Two Critical and Functionally Distinct Stages of Face and Body Perception. Journal of Neuroscience, 32(45), 15877&ndash;15885. </p>
      <p>Troje, N. F., &amp; Westhoff, C. (2006). The inversion effect in biological motion perception: evidence for a &ldquo;life detector?&rdquo; Current Biology, 16(8), 821&ndash;824. http://doi.org/10.1016/j.cub.2006.03.022</p>
      <p>&nbsp;</p></td>
    <td><p>&nbsp;</p></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td><div align="center">
      <p><strong>Additional topics: human hands, gestures, detecting artifacts</strong></p>
    </div></td>
    <td><p>Orlov, T., Porat, Y., Makin, T. R., &amp; Zohary, E. (2014). Hands in Motion: An Upper-Limb-Selective Area in the Occipitotemporal Cortex Shows Sensitivity to Viewed Hand Kinematics. Journal of Neuroscience, 34(14), 4882&ndash;4895. </p>
      <p>Dayan, E., Casile, A., Levit-Binnun, N., Giese, M. A., Hendler, T., &amp; Flash, T. (2007). Neural representations of kinematic laws of motion: evidence for action-perception coupling. Proceedings of the National Academy of Sciences, 104(51), 20582&ndash;20587.</p></td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td><div align="center"></div></td>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
</table>
<h2></h2>
<h2 align="center">&nbsp;</h2>
</BODY>
</HTML>
